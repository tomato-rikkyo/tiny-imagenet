{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow 2.3でメモリを指定及び節約して使うためのおまじない。\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(physical_devices[4], 'GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[4], True)\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "np.random.seed(219)\n",
    "random.seed(219)\n",
    "tf.random.set_seed(219)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dirpath = \"/workdir/taki_lab/tiny-imagenet-200/\"\n",
    "train_dir = os.path.join(dirpath, \"train\")\n",
    "val_dir = os.path.join(dirpath, \"val\")\n",
    "test_dir = os.path.join(dirpath, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 images belonging to 200 classes.\n",
      "Found 10000 images belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "N_TRAIN = 100000\n",
    "N_VAL = 10000\n",
    "INPUT_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_gen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                              rotation_range=10,\n",
    "                              width_shift_range=0.1,\n",
    "                              height_shift_range=0.1,\n",
    "                              shear_range=0.1,\n",
    "                              zoom_range=0.1,\n",
    "                              fill_mode=\"nearest\")\n",
    "\n",
    "val_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_gen.flow_from_directory(train_dir,\n",
    "                                               target_size=INPUT_SIZE,\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               class_mode=\"categorical\")\n",
    "\n",
    "val_generator = val_gen.flow_from_directory(val_dir,\n",
    "                                           target_size=INPUT_SIZE,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, Model\n",
    "\n",
    "class CBR(Model):\n",
    "    def __init__(self, filters, kernel_size, strides):\n",
    "        super().__init__()\n",
    "        params = {\n",
    "            \"filters\":filters,\n",
    "            \"kernel_size\":kernel_size,\n",
    "            \"strides\":strides,\n",
    "            \"padding\":\"same\",\n",
    "            \"use_bias\":True,\n",
    "            \"kernel_initializer\":\"he_normal\"\n",
    "        }\n",
    "        \n",
    "        self.layers_ = [\n",
    "            layers.Conv2D(**params),\n",
    "            layers.ReLU(),\n",
    "            layers.BatchNormalization()\n",
    "        ]\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        for layer in self.layers_:\n",
    "            inputs = layer(inputs)\n",
    "        return inputs\n",
    "\n",
    "class VGG16(Model):\n",
    "    def __init__(self, output_size):\n",
    "        super().__init__()\n",
    "        self.layers_ = [\n",
    "            CBR(64, 3, 1),\n",
    "            CBR(64, 3, 1),\n",
    "            layers.MaxPool2D((2,2)),\n",
    "            CBR(128, 3, 1),\n",
    "            CBR(128, 3, 1),\n",
    "            layers.MaxPool2D((2,2)),\n",
    "            CBR(256, 3, 1),\n",
    "            CBR(256, 3, 1),\n",
    "            CBR(256, 3, 1),\n",
    "            layers.MaxPool2D((2,2)),\n",
    "            CBR(256, 3, 1),\n",
    "            CBR(256, 3, 1),\n",
    "            CBR(256, 3, 1),\n",
    "            layers.MaxPool2D((2,2)),\n",
    "            CBR(512, 3, 1),\n",
    "            CBR(512, 3, 1),\n",
    "            CBR(512, 3, 1),\n",
    "            layers.MaxPool2D((2,2)),\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.Dense(4096, kernel_initializer=\"he_normal\"),\n",
    "            layers.Dense(output_size, activation=\"softmax\")\n",
    "        ]\n",
    "    \n",
    "    def call(self,inputs):\n",
    "        for layer in self.layers_:\n",
    "            inputs = layer(inputs)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/tomato-ai/tiny-image-net\" target=\"_blank\">https://app.wandb.ai/tomato-ai/tiny-image-net</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/tomato-ai/tiny-image-net/runs/342l7jha\" target=\"_blank\">https://app.wandb.ai/tomato-ai/tiny-image-net/runs/342l7jha</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.10.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3124/3125 [============================>.] - ETA: 0s - loss: 6.7410 - acc: 0.0219WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 6.7405 - acc: 0.0219WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model, h5py returned error: Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 835s 267ms/step - loss: 6.7405 - acc: 0.0219 - val_loss: 6.1659 - val_acc: 0.0232\n",
      "Epoch 2/1000\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3124/3125 [============================>.] - ETA: 0s - loss: 5.1958 - acc: 0.0315WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 5.1955 - acc: 0.0315WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - 841s 269ms/step - loss: 5.1955 - acc: 0.0315 - val_loss: 36872704.0000 - val_acc: 0.0280\n",
      "Epoch 3/1000\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3124/3125 [============================>.] - ETA: 0s - loss: 5.1070 - acc: 0.0505WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 5.1069 - acc: 0.0505WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - 828s 265ms/step - loss: 5.1069 - acc: 0.0505 - val_loss: 168835.5938 - val_acc: 0.0321\n",
      "Epoch 4/1000\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3124/3125 [============================>.] - ETA: 0s - loss: 4.1207 - acc: 0.1151WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 4.1206 - acc: 0.1151WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - 833s 266ms/step - loss: 4.1206 - acc: 0.1151 - val_loss: 103.8786 - val_acc: 0.1031\n",
      "Epoch 5/1000\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3124/3125 [============================>.] - ETA: 0s - loss: 3.9723 - acc: 0.1388WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 3.9721 - acc: 0.1388WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - 834s 267ms/step - loss: 3.9721 - acc: 0.1388 - val_loss: 5.0514 - val_acc: 0.1021\n",
      "Epoch 6/1000\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3124/3125 [============================>.] - ETA: 0s - loss: 3.8252 - acc: 0.1604WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 3.8252 - acc: 0.1603WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - 831s 266ms/step - loss: 3.8252 - acc: 0.1603 - val_loss: 3817.2583 - val_acc: 0.1716\n",
      "Epoch 7/1000\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3124/3125 [============================>.] - ETA: 0s - loss: 3.6875 - acc: 0.1821WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 3.6877 - acc: 0.1821WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - 827s 265ms/step - loss: 3.6877 - acc: 0.1821 - val_loss: 9336.4805 - val_acc: 0.2030\n",
      "Epoch 8/1000\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3124/3125 [============================>.] - ETA: 0s - loss: 3.2453 - acc: 0.2516WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 3.2452 - acc: 0.2516WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - 819s 262ms/step - loss: 3.2452 - acc: 0.2516 - val_loss: 45.4899 - val_acc: 0.2387\n",
      "Epoch 9/1000\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3124/3125 [============================>.] - ETA: 0s - loss: 3.1414 - acc: 0.2696WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 3.1413 - acc: 0.2697WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - 821s 263ms/step - loss: 3.1413 - acc: 0.2697 - val_loss: 671.0554 - val_acc: 0.2579\n",
      "Epoch 10/1000\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3124/3125 [============================>.] - ETA: 0s - loss: 2.9073 - acc: 0.3145WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 2.9073 - acc: 0.3145WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - 818s 262ms/step - loss: 2.9073 - acc: 0.3145 - val_loss: 15776.5518 - val_acc: 0.3135\n",
      "Epoch 11/1000\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3124/3125 [============================>.] - ETA: 0s - loss: 2.8398 - acc: 0.3267WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 2.8397 - acc: 0.3267WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - 832s 266ms/step - loss: 2.8397 - acc: 0.3267 - val_loss: 581249.7500 - val_acc: 0.3324\n",
      "Epoch 12/1000\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3124/3125 [============================>.] - ETA: 0s - loss: 2.7072 - acc: 0.3549WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 2.7072 - acc: 0.3549WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - 832s 266ms/step - loss: 2.7072 - acc: 0.3549 - val_loss: 210721.5938 - val_acc: 0.3548\n",
      "Epoch 13/1000\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3124/3125 [============================>.] - ETA: 0s - loss: 2.6636 - acc: 0.3649WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 2.6636 - acc: 0.3650WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - 844s 270ms/step - loss: 2.6636 - acc: 0.3650 - val_loss: 55793.2227 - val_acc: 0.3558\n",
      "Epoch 14/1000\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3124/3125 [============================>.] - ETA: 0s - loss: 2.5857 - acc: 0.3812WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 2.5855 - acc: 0.3813WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - 837s 268ms/step - loss: 2.5855 - acc: 0.3813 - val_loss: 15520.0898 - val_acc: 0.3688\n",
      "Epoch 15/1000\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3124/3125 [============================>.] - ETA: 0s - loss: 2.5562 - acc: 0.3864WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 2.5562 - acc: 0.3863WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - 836s 267ms/step - loss: 2.5562 - acc: 0.3863 - val_loss: 97450.6641 - val_acc: 0.3755\n",
      "Epoch 16/1000\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3124/3125 [============================>.] - ETA: 0s - loss: 2.5128 - acc: 0.3956WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 2.5127 - acc: 0.3956WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - 839s 269ms/step - loss: 2.5127 - acc: 0.3956 - val_loss: 95027.8906 - val_acc: 0.3845\n",
      "Epoch 17/1000\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3124/3125 [============================>.] - ETA: 0s - loss: 2.4968 - acc: 0.4001WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 2.4968 - acc: 0.4001WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - 838s 268ms/step - loss: 2.4968 - acc: 0.4001 - val_loss: 41088.2617 - val_acc: 0.3837\n",
      "Epoch 18/1000\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3124/3125 [============================>.] - ETA: 0s - loss: 2.4705 - acc: 0.4041WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 2.4706 - acc: 0.4040WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - 841s 269ms/step - loss: 2.4706 - acc: 0.4040 - val_loss: 5391.7979 - val_acc: 0.3903\n",
      "Epoch 19/1000\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3124/3125 [============================>.] - ETA: 0s - loss: 2.4623 - acc: 0.4057WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 2.4623 - acc: 0.4058WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - 842s 270ms/step - loss: 2.4623 - acc: 0.4058 - val_loss: 12178.3867 - val_acc: 0.3914\n",
      "Epoch 20/1000\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3124/3125 [============================>.] - ETA: 0s - loss: 2.4517 - acc: 0.4082WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 2.4518 - acc: 0.4082WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - 841s 269ms/step - loss: 2.4518 - acc: 0.4082 - val_loss: 23311.2637 - val_acc: 0.3900\n",
      "Epoch 21/1000\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3124/3125 [============================>.] - ETA: 0s - loss: 2.4447 - acc: 0.4102WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 2.4449 - acc: 0.4102WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - 839s 268ms/step - loss: 2.4449 - acc: 0.4102 - val_loss: 9062.5645 - val_acc: 0.3930\n",
      "Epoch 22/1000\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3124/3125 [============================>.] - ETA: 0s - loss: 2.4381 - acc: 0.4110WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 2.4381 - acc: 0.4109WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "3125/3125 [==============================] - 839s 269ms/step - loss: 2.4381 - acc: 0.4109 - val_loss: 30843.7754 - val_acc: 0.3923\n",
      "Epoch 23/1000\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "1241/3125 [==========>...................] - ETA: 8:04 - loss: 2.4308 - acc: 0.4152"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# wandbの設定\n",
    "wandb.init(project=\"tiny-image-net\", name=\"vgg16_normal\")\n",
    "config = wandb.config\n",
    "config.learning_rate = 0.01\n",
    "config.lr_factor = 0.5\n",
    "config.optimaizer = \"Adam\"\n",
    "config.batch_size = BATCH_SIZE\n",
    "config.input_size = INPUT_SIZE\n",
    "config.rotation_range = 10\n",
    "config.width_shift_range = 0.1\n",
    "config.height_shift_range = 0.1\n",
    "config.shear_range = 0.1\n",
    "config.zoom_range = 0.1\n",
    "\n",
    "# 最適化設定\n",
    "\n",
    "model = VGG16(200)\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.01),\n",
    "             loss=\"categorical_crossentropy\",\n",
    "             metrics=[\"acc\"])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_acc\", patience=5)\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-5)\n",
    "\n",
    "callback_list = [early_stopping, reduce_lr, WandbCallback()]\n",
    "\n",
    "\n",
    "# 学習\n",
    "history = model.fit(train_generator,\n",
    "    steps_per_epoch=N_TRAIN//BATCH_SIZE ,\n",
    "    epochs=1000,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=N_VAL//BATCH_SIZE,\n",
    "    use_multiprocessing=True,\n",
    "    workers=24,\n",
    "    callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
